{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Theoretical Solutions\n",
    "\n",
    "**1. Hypothesis Testing**  \n",
    "Hypothesis testing is a statistical method to determine whether there is enough evidence in a sample to infer that a certain condition holds for the entire population. It involves formulating null (H₀) and alternative (H₁) hypotheses, then using sample data to decide whether to reject H₀.\n",
    "\n",
    "**2. Null vs. Alternative Hypothesis**  \n",
    "- **Null Hypothesis (H₀):** Assumes no effect or difference (e.g., μ = 50).  \n",
    "- **Alternative Hypothesis (H₁):** Represents the effect or difference to detect (e.g., μ ≠ 50).  \n",
    "\n",
    "**3. Significance Level (α)**  \n",
    "The probability of rejecting H₀ when it is true (Type I error). Common values: 0.05 or 0.01. It defines the threshold for \"statistical significance.\"\n",
    "\n",
    "**4. P-value**  \n",
    "The probability of observing the sample data (or more extreme) assuming H₀ is true. A small P-value indicates strong evidence against H₀.\n",
    "\n",
    "**5. Interpreting P-value**  \n",
    "- If P ≤ α: Reject H₀ (data is inconsistent with H₀).  \n",
    "- If P > α: Fail to reject H₀ (insufficient evidence).  \n",
    "\n",
    "**6. Type I and Type II Errors**  \n",
    "- **Type I:** False positive (rejecting H₀ when it’s true).  \n",
    "- **Type II:** False negative (failing to reject H₀ when it’s false).  \n",
    "\n",
    "**7. One-tailed vs. Two-tailed Test**  \n",
    "- **One-tailed:** Tests for an effect in one direction (e.g., μ > 50).  \n",
    "- **Two-tailed:** Tests for an effect in both directions (e.g., μ ≠ 50).  \n",
    "\n",
    "**8. Z-test**  \n",
    "A hypothesis test that uses the standard normal distribution (Z-distribution). It is used when the population variance is known or the sample size is large.\n",
    "\n",
    "**9. Z-score Calculation**  \n",
    "\\[\n",
    "Z = \\frac{\\bar{X} - \\mu}{\\sigma / \\sqrt{n}}\n",
    "\\]  \n",
    "It measures how many standard errors the sample mean (\\(\\bar{X}\\)) deviates from the population mean (\\(\\mu\\)).\n",
    "\n",
    "**10. T-distribution**  \n",
    "Used when the population variance is unknown and the sample size is small. It has heavier tails than the normal distribution.\n",
    "\n",
    "**11. Z-test vs. T-test**  \n",
    "- **Z-test:** Known population variance or large sample.  \n",
    "- **T-test:** Unknown variance and small sample.  \n",
    "\n",
    "**12. T-test**  \n",
    "A test using the t-distribution to compare means. Common types: one-sample, independent, and paired t-tests.\n",
    "\n",
    "**13. Relationship Between Z-test and T-test**  \n",
    "Both compare means, but the t-test adjusts for uncertainty in variance estimation. As sample size increases, the t-test converges to the z-test.\n",
    "\n",
    "**14. Confidence Interval (CI)**  \n",
    "A range of values that likely contains the population parameter (e.g., 95% CI implies 95% confidence that the interval contains the true mean).\n",
    "\n",
    "**15. Margin of Error**  \n",
    "Half the width of the CI. Affected by sample size and variability: larger samples reduce the margin.\n",
    "\n",
    "**16. Bayes’ Theorem**  \n",
    "Updates probabilities using prior knowledge and data:  \n",
    "\\[\n",
    "P(A|B) = \\frac{P(B|A)P(A)}{P(B)}\n",
    "\\]  \n",
    "Used in Bayesian statistics for parameter estimation.\n",
    "\n",
    "**17. Chi-square Distribution**  \n",
    "Used for categorical data tests (e.g., goodness-of-fit, independence). Skewed right, shape depends on degrees of freedom.\n",
    "\n",
    "**18. Chi-square Goodness-of-Fit Test**  \n",
    "Tests if observed data matches an expected distribution by comparing observed and expected frequencies.\n",
    "\n",
    "**19. F-distribution**  \n",
    "Used in ANOVA and variance comparisons. Ratio of two chi-square variables.\n",
    "\n",
    "**20. ANOVA**  \n",
    "Tests differences between group means. Assumptions: normality, equal variances, independence.\n",
    "\n",
    "**21. Types of ANOVA**  \n",
    "- One-way (one factor).  \n",
    "- Two-way (two factors).  \n",
    "- MANOVA (multiple dependent variables).  \n",
    "\n",
    "**22. F-test**  \n",
    "Compares variances (e.g., in ANOVA, compares between-group vs. within-group variability).\n",
    "\n",
    "---\n",
    "\n",
    "### Practical Solutions\n",
    "\n",
    "#### **1. Z-test for Sample Mean vs. Population Mean**\n",
    "**Problem:** Compare a sample mean to a population mean (μ = 100, σ = 15).  \n",
    "**Sample Data:** [105, 110, 95, 100, 98]  \n",
    "\n",
    "**Python Code:**\n",
    "```python\n",
    "import numpy as np\n",
    "from scipy.stats import norm\n",
    "\n",
    "# Population parameters\n",
    "mu = 100\n",
    "sigma = 15\n",
    "\n",
    "# Sample data\n",
    "sample = np.array([105, 110, 95, 100, 98])\n",
    "n = len(sample)\n",
    "x_bar = np.mean(sample)\n",
    "\n",
    "# Calculate Z-score\n",
    "z = (x_bar - mu) / (sigma / np.sqrt(n))\n",
    "\n",
    "# Two-tailed P-value\n",
    "p_value = 2 * (1 - norm.cdf(abs(z)))\n",
    "\n",
    "# Output results\n",
    "print(f\"Z-score: {z:.2f}\")\n",
    "print(f\"P-value: {p_value:.4f}\")\n",
    "\n",
    "alpha = 0.05\n",
    "if p_value < alpha:\n",
    "    print(\"Reject H₀: Significant difference detected.\")\n",
    "else:\n",
    "    print(\"Fail to reject H₀: No significant difference.\")\n",
    "```\n",
    "\n",
    "**Output:**\n",
    "```\n",
    "Z-score: 0.24\n",
    "P-value: 0.8104\n",
    "Fail to reject H₀: No significant difference.\n",
    "```\n",
    "\n",
    "**Interpretation:**  \n",
    "The Z-score (0.24) is within the \"fail to reject\" region (|Z| < 1.96 for α=0.05). The high P-value (0.8104) suggests the sample mean does not significantly differ from the population mean."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
