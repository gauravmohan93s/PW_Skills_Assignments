{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Statistics Assignment: Theoretical Solutions\n",
    "\n",
    "---\n",
    "\n",
    "## **1. Hypothesis Testing in Statistics**  \n",
    "Hypothesis testing is a method to determine if there is enough statistical evidence to support a claim about a population parameter. It involves:  \n",
    "- **Null Hypothesis ($(H_0$))**: Assumes no effect/difference.  \n",
    "- **Alternative Hypothesis ($(H_1$))**: Represents the researcher’s claim.  \n",
    "- **Test Statistic**: Computed from sample data (e.g., $(Z$), $(T$)).  \n",
    "- **Decision Rule**: Compare the test statistic to a critical value or use a **P-value**.  \n",
    "\n",
    "**Example**:  \n",
    "Testing if a new drug lowers blood pressure:  \n",
    "- $(H_0$): Drug has no effect ($(\\mu = \\mu_0$)).  \n",
    "- $(H_1$): Drug reduces blood pressure ($(\\mu < \\mu_0$)).  \n",
    "\n",
    "---\n",
    "\n",
    "## **2. Null Hypothesis vs. Alternative Hypothesis**  \n",
    "- **Null Hypothesis (\\(H_0\\))**: Default assumption (e.g., \\(\\mu = 50\\)).  \n",
    "- **Alternative Hypothesis (\\(H_1\\))**: Contradicts \\(H_0\\) (e.g., \\(\\mu \\neq 50\\) or \\(\\mu > 50\\)).  \n",
    "\n",
    "**Key Difference**:  \n",
    "- \\(H_0\\) is tested for rejection; \\(H_1\\) is the claim to validate.  \n",
    "\n",
    "---\n",
    "\n",
    "## **3. Significance Level (\\(\\alpha\\))**  \n",
    "- The probability of rejecting \\(H_0\\) when it is true (**Type I error**).  \n",
    "- Common values: \\(\\alpha = 0.05\\) or \\(\\alpha = 0.01\\).  \n",
    "- **Importance**: Controls the risk of false positives.  \n",
    "\n",
    "---\n",
    "\n",
    "## **4. P-value**  \n",
    "- The probability of observing the sample data (or more extreme results) **assuming \\(H_0\\) is true**.  \n",
    "- **Formula**:  \n",
    "  \\[\n",
    "  P\\text{-value} = P(\\text{Test Statistic} \\geq \\text{Observed Value} \\mid H_0)\n",
    "  \\]  \n",
    "**Example**:  \n",
    "If \\(P = 0.03\\) and \\(\\alpha = 0.05\\), reject \\(H_0\\).  \n",
    "\n",
    "---\n",
    "\n",
    "## **5. Interpreting the P-value**  \n",
    "- **Low \\(P\\)-value** (\\(P < \\alpha\\)): Strong evidence against \\(H_0\\).  \n",
    "- **High \\(P\\)-value** (\\(P \\geq \\alpha\\)): Insufficient evidence to reject \\(H_0\\).  \n",
    "\n",
    "---\n",
    "\n",
    "## **6. Type I and Type II Errors**  \n",
    "- **Type I Error**: Rejecting \\(H_0\\) when it is true (\\(\\alpha\\)).  \n",
    "  - Example: Concluding a drug works when it does not.  \n",
    "- **Type II Error (\\(\\beta\\))**: Failing to reject \\(H_0\\) when it is false.  \n",
    "  - Example: Failing to detect a drug’s effect.  \n",
    "\n",
    "---\n",
    "\n",
    "## **7. One-Tailed vs. Two-Tailed Tests**  \n",
    "- **One-Tailed**: Tests for an effect in **one direction** (e.g., \\(\\mu > 50\\)).  \n",
    "  - Critical region in one tail of the distribution.  \n",
    "- **Two-Tailed**: Tests for effects in **both directions** (e.g., \\(\\mu \\neq 50\\)).  \n",
    "  - Critical regions in both tails.  \n",
    "\n",
    "---\n",
    "\n",
    "## **8. Z-Test**  \n",
    "- A hypothesis test using the **standard normal distribution** (\\(Z\\)-distribution).  \n",
    "- **Use Case**:  \n",
    "  - Population variance (\\(\\sigma^2\\)) is known.  \n",
    "  - Large sample size (\\(n \\geq 30\\)).  \n",
    "\n",
    "**Formula**:  \n",
    "\\[\n",
    "Z = \\frac{\\bar{X} - \\mu}{\\sigma / \\sqrt{n}}\n",
    "\\]  \n",
    "Where:  \n",
    "- \\(\\bar{X}\\) = Sample mean  \n",
    "- \\(\\mu\\) = Population mean  \n",
    "- \\(\\sigma\\) = Population standard deviation  \n",
    "- \\(n\\) = Sample size  \n",
    "\n",
    "---\n",
    "\n",
    "## **9. Z-Score Calculation**  \n",
    "- Measures how many standard errors the sample mean deviates from the population mean.  \n",
    "\\[\n",
    "Z = \\frac{\\bar{X} - \\mu}{\\sigma / \\sqrt{n}}\n",
    "\\]  \n",
    "**Interpretation**:  \n",
    "- \\(Z = 1.96\\) → Sample mean is 1.96 standard errors above \\(\\mu\\).  \n",
    "\n",
    "---\n",
    "\n",
    "## **10. T-Distribution**  \n",
    "- A distribution with **heavier tails** than the normal distribution.  \n",
    "- **Use Case**:  \n",
    "  - Population variance unknown.  \n",
    "  - Small sample size (\\(n < 30\\)).  \n",
    "- **Degrees of Freedom**: \\(df = n - 1\\).  \n",
    "\n",
    "---\n",
    "\n",
    "## **11. Z-Test vs. T-Test**  \n",
    "| **Z-Test** | **T-Test** |  \n",
    "|------------|------------|  \n",
    "| Uses \\(\\sigma\\) (known variance). | Uses \\(s\\) (sample variance). |  \n",
    "| Suitable for large samples. | Suitable for small samples. |  \n",
    "\n",
    "---\n",
    "\n",
    "## **12. T-Test**  \n",
    "- Compares means using the **T-distribution**.  \n",
    "- **Types**:  \n",
    "  1. **One-Sample**: Compare sample mean to a known \\(\\mu\\).  \n",
    "  2. **Independent**: Compare two independent groups.  \n",
    "  3. **Paired**: Compare paired observations (e.g., pre-test vs. post-test).  \n",
    "\n",
    "**Formula (One-Sample)**:  \n",
    "\\[\n",
    "t = \\frac{\\bar{X} - \\mu}{s / \\sqrt{n}}\n",
    "\\]  \n",
    "Where \\(s\\) = sample standard deviation.  \n",
    "\n",
    "---\n",
    "\n",
    "## **13. Relationship Between Z-Test and T-Test**  \n",
    "- Both compare means, but the T-test accounts for uncertainty in estimating \\(\\sigma\\).  \n",
    "- As \\(n \\to \\infty\\), the T-distribution converges to the Z-distribution.  \n",
    "\n",
    "---\n",
    "\n",
    "## **14. Confidence Interval (CI)**  \n",
    "- A range of values that likely contains the population parameter.  \n",
    "- **Formula for Mean**:  \n",
    "\\[\n",
    "\\text{CI} = \\bar{X} \\pm Z_{\\alpha/2} \\cdot \\frac{\\sigma}{\\sqrt{n}}\n",
    "\\]  \n",
    "**Example**: 95% CI = \\([45, 55]\\) → 95% confidence the true mean lies in this interval.  \n",
    "\n",
    "---\n",
    "\n",
    "## **15. Margin of Error**  \n",
    "- Half the width of the confidence interval.  \n",
    "\\[\n",
    "\\text{Margin of Error} = Z_{\\alpha/2} \\cdot \\frac{\\sigma}{\\sqrt{n}}\n",
    "\\]  \n",
    "- **Impact**: Larger \\(n\\) reduces the margin of error.  \n",
    "\n",
    "---\n",
    "\n",
    "## **16. Bayes’ Theorem**  \n",
    "\\[\n",
    "P(A|B) = \\frac{P(B|A) \\cdot P(A)}{P(B)}\n",
    "\\]  \n",
    "- **Application**: Updates prior beliefs (\\(P(A)\\)) with data (\\(P(B|A)\\)).  \n",
    "- **Example**: Spam detection (updating spam probability based on keywords).  \n",
    "\n",
    "---\n",
    "\n",
    "## **17. Chi-Square Distribution**  \n",
    "- A right-skewed distribution for **categorical data analysis**.  \n",
    "- **Use Cases**:  \n",
    "  - Goodness-of-fit tests.  \n",
    "  - Tests of independence.  \n",
    "\n",
    "---\n",
    "\n",
    "## **18. Chi-Square Goodness-of-Fit Test**  \n",
    "- Tests if observed data matches an expected distribution.  \n",
    "- **Formula**:  \n",
    "\\[\n",
    "\\chi^2 = \\sum \\frac{(O_i - E_i)^2}{E_i}\n",
    "\\]  \n",
    "Where:  \n",
    "- \\(O_i\\) = Observed frequency  \n",
    "- \\(E_i\\) = Expected frequency  \n",
    "\n",
    "**Example**: Testing if a die is fair (\\(E_i = \\frac{n}{6}\\)).  \n",
    "\n",
    "---\n",
    "\n",
    "## **19. F-Distribution**  \n",
    "- The distribution of the ratio of two chi-square variables.  \n",
    "- **Use Cases**:  \n",
    "  - ANOVA (comparing group variances).  \n",
    "  - Testing equality of variances.  \n",
    "\n",
    "---\n",
    "\n",
    "## **20. ANOVA Test**  \n",
    "- **Analysis of Variance (ANOVA)** tests differences between group means.  \n",
    "- **Assumptions**:  \n",
    "  1. Normality.  \n",
    "  2. Homogeneity of variances.  \n",
    "  3. Independence.  \n",
    "\n",
    "**Formula (F-statistic)**:  \n",
    "\\[\n",
    "F = \\frac{\\text{Between-group variance}}{\\text{Within-group variance}}\n",
    "\\]  \n",
    "\n",
    "---\n",
    "\n",
    "## **21. Types of ANOVA**  \n",
    "1. **One-Way ANOVA**: Tests one factor (e.g., effect of fertilizer on plant growth).  \n",
    "2. **Two-Way ANOVA**: Tests two factors and their interaction.  \n",
    "3. **MANOVA**: Tests multiple dependent variables.  \n",
    "\n",
    "---\n",
    "\n",
    "## **22. F-Test**  \n",
    "- Compares variances using the **F-distribution**.  \n",
    "- **In ANOVA**: Compares variability between groups to variability within groups.  \n",
    "\n",
    "**Formula**:  \n",
    "\\[\n",
    "F = \\frac{MS_{\\text{between}}}{MS_{\\text{within}}}\n",
    "\\]  \n",
    "Where \\(MS\\) = Mean Square.  \n",
    "\n",
    "---"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
