{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Detailed Solutions to the Assignment Questions\n",
    "\n",
    "---\n",
    "\n",
    "### **1. Properties of the F-Distribution**\n",
    "\n",
    "The **F-distribution** is a continuous probability distribution that arises frequently in statistical tests, particularly in the analysis of variance (ANOVA) and regression analysis. Here are its key properties:\n",
    "\n",
    "- **Shape**: The F-distribution is positively skewed, meaning it has a long tail to the right. The shape of the distribution depends on two parameters: the degrees of freedom of the numerator ($(df_1$)) and the degrees of freedom of the denominator ($(df_2$)).\n",
    "  \n",
    "- **Range**: The F-distribution is defined only for non-negative values ($(F \\geq 0$)).\n",
    "\n",
    "- **Degrees of Freedom**: The F-distribution has two degrees of freedom parameters: one for the numerator and one for the denominator. These degrees of freedom depend on the sample sizes and the number of groups being compared.\n",
    "\n",
    "- **Asymptotic Behavior**: As the degrees of freedom increase, the F-distribution approaches a normal distribution.\n",
    "\n",
    "- **Relationship to Other Distributions**: The F-distribution is related to the **chi-squared distribution** and the **t-distribution**. Specifically, the ratio of two chi-squared distributed variables divided by their degrees of freedom follows an F-distribution.\n",
    "\n",
    "---\n",
    "\n",
    "### **2. Use of the F-Distribution in Statistical Tests**\n",
    "\n",
    "The F-distribution is used in the following statistical tests:\n",
    "\n",
    "- **ANOVA (Analysis of Variance)**: ANOVA uses the F-distribution to test whether the means of several groups are equal. It compares the variance between groups to the variance within groups.\n",
    "\n",
    "- **F-Test for Comparing Variances**: The F-test is used to compare the variances of two populations. It tests the null hypothesis that the variances are equal.\n",
    "\n",
    "- **Regression Analysis**: In regression, the F-test is used to test the overall significance of the model by comparing the model's explained variance to the unexplained variance.\n",
    "\n",
    "The F-distribution is appropriate for these tests because it is derived from the ratio of two variances, which is a natural way to compare variability in different contexts.\n",
    "\n",
    "---\n",
    "\n",
    "### **3. Key Assumptions for Conducting an F-Test**\n",
    "\n",
    "To conduct an F-test to compare the variances of two populations, the following assumptions must be met:\n",
    "\n",
    "1. **Normality**: The data in both populations should be normally distributed.\n",
    "2. **Independence**: The samples from the two populations should be independent of each other.\n",
    "3. **Random Sampling**: The data should be collected through random sampling.\n",
    "4. **Homogeneity of Variance**: The F-test assumes that the variances of the populations are equal (this is the null hypothesis being tested).\n",
    "\n",
    "---\n",
    "\n",
    "### **4. Purpose of ANOVA and How It Differs from a t-Test**\n",
    "\n",
    "- **Purpose of ANOVA**: ANOVA (Analysis of Variance) is used to compare the means of three or more groups to determine if there are any statistically significant differences between them.\n",
    "\n",
    "- **Difference from a t-Test**: A t-test is used to compare the means of **two** groups, while ANOVA is used for **three or more** groups. ANOVA avoids the problem of multiple comparisons that arises when using multiple t-tests, which can inflate the Type I error rate.\n",
    "\n",
    "---\n",
    "\n",
    "### **5. When and Why to Use One-Way ANOVA Instead of Multiple t-Tests**\n",
    "\n",
    "- **When to Use One-Way ANOVA**: One-way ANOVA is used when comparing the means of **three or more** groups.\n",
    "\n",
    "- **Why Use One-Way ANOVA**: Using multiple t-tests to compare more than two groups increases the likelihood of making a Type I error (false positive). ANOVA controls the overall Type I error rate by performing a single test to compare all groups simultaneously.\n",
    "\n",
    "---\n",
    "\n",
    "### **6. Partitioning Variance in ANOVA**\n",
    "\n",
    "In ANOVA, the total variance in the data is partitioned into two components:\n",
    "\n",
    "1. **Between-Group Variance**: This measures the variability between the group means. It reflects the differences due to the treatment or group effect.\n",
    "2. **Within-Group Variance**: This measures the variability within each group. It reflects the random error or noise in the data.\n",
    "\n",
    "The **F-statistic** is calculated as the ratio of the between-group variance to the within-group variance:\n",
    "\n",
    "$$[\n",
    "F = \\frac{\\text{Between-Group Variance}}{\\text{Within-Group Variance}}\n",
    "$$]\n",
    "\n",
    "A high F-statistic indicates that the between-group variance is significantly larger than the within-group variance, suggesting that the group means are different.\n",
    "\n",
    "---\n",
    "\n",
    "### **7. Classical (Frequentist) vs. Bayesian Approach to ANOVA**\n",
    "\n",
    "- **Classical (Frequentist) Approach**:\n",
    "  - **Uncertainty**: Handles uncertainty through p-values and confidence intervals.\n",
    "  - **Parameter Estimation**: Uses maximum likelihood estimation (MLE) to estimate parameters.\n",
    "  - **Hypothesis Testing**: Tests hypotheses using p-values and fixed significance levels (e.g., 0.05).\n",
    "\n",
    "- **Bayesian Approach**:\n",
    "  - **Uncertainty**: Handles uncertainty through posterior distributions and credible intervals.\n",
    "  - **Parameter Estimation**: Uses prior distributions and updates them with data to obtain posterior distributions.\n",
    "  - **Hypothesis Testing**: Compares models using Bayes factors or posterior probabilities.\n",
    "\n",
    "The key difference is that the Bayesian approach incorporates prior knowledge and provides a probabilistic interpretation of parameters, while the frequentist approach relies on long-run frequency properties.\n",
    "\n",
    "---\n",
    "\n",
    "### **8. F-Test to Compare Variances of Two Professions' Incomes**\n",
    "\n",
    "Given data:\n",
    "- **Profession A**: [48, 52, 55, 60, 62]\n",
    "- **Profession B**: [45, 50, 55, 52, 47]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F-statistic: 2.089171974522293\n",
      "P-value: 0.49304859900533904\n"
     ]
    }
   ],
   "source": [
    "# **Python Code to Perform F-Test**:\n",
    "\n",
    "import numpy as np\n",
    "from scipy.stats import f\n",
    "\n",
    "# Data\n",
    "A = np.array([48, 52, 55, 60, 62])\n",
    "B = np.array([45, 50, 55, 52, 47])\n",
    "\n",
    "# Calculate variances\n",
    "var_A = np.var(A, ddof=1)\n",
    "var_B = np.var(B, ddof=1)\n",
    "\n",
    "# F-statistic\n",
    "F = var_A / var_B if var_A > var_B else var_B / var_A\n",
    "\n",
    "# Degrees of freedom\n",
    "df_A = len(A) - 1\n",
    "df_B = len(B) - 1\n",
    "\n",
    "# P-value\n",
    "p_value = 2 * min(f.cdf(F, df_A, df_B), 1 - f.cdf(F, df_A, df_B))\n",
    "\n",
    "print(f\"F-statistic: {F}\")\n",
    "print(f\"P-value: {p_value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Interpretation**:\n",
    "- If the p-value is less than 0.05, we reject the null hypothesis and conclude that the variances are not equal.\n",
    "- If the p-value is greater than 0.05, we fail to reject the null hypothesis and conclude that the variances are equal.\n",
    "\n",
    "---\n",
    "\n",
    "### **9. One-Way ANOVA to Compare Average Heights in Three Regions**\n",
    "\n",
    "Given data:\n",
    "- **Region A**: [160, 162, 165, 158, 164]\n",
    "- **Region B**: [172, 175, 170, 168, 174]\n",
    "- **Region C**: [180, 182, 179, 185, 183]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F-statistic: 67.87330316742101\n",
      "P-value: 2.8706641879370255e-07\n"
     ]
    }
   ],
   "source": [
    "# **Python Code to Perform One-Way ANOVA**:\n",
    "\n",
    "from scipy.stats import f_oneway\n",
    "\n",
    "# Data\n",
    "A = [160, 162, 165, 158, 164]\n",
    "B = [172, 175, 170, 168, 174]\n",
    "C = [180, 182, 179, 185, 183]\n",
    "\n",
    "# Perform one-way ANOVA\n",
    "F_statistic, p_value = f_oneway(A, B, C)\n",
    "\n",
    "print(f\"F-statistic: {F_statistic}\")\n",
    "print(f\"P-value: {p_value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Interpretation**:\n",
    "- If the p-value is less than 0.05, we reject the null hypothesis and conclude that there are statistically significant differences in average heights between the regions.\n",
    "- If the p-value is greater than 0.05, we fail to reject the null hypothesis and conclude that there are no significant differences.\n",
    "\n",
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
