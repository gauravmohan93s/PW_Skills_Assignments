{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment: Files & Exceptional Handling\n",
    "\n",
    "## 1. Discuss the scenarios where multithreading is preferable to multiprocessing and scenarios where multiprocessing is a better choice."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Multithreading vs. Multiprocessing: Scenarios and Use Cases**\n",
    "\n",
    "**Multithreading** and **multiprocessing** are both ways of achieving parallelism in Python, but they are suited to different types of tasks. Here's a detailed discussion of scenarios where one is preferable over the other.\n",
    "\n",
    "---\n",
    "\n",
    "### **Multithreading**\n",
    "\n",
    "**Multithreading** involves multiple threads running within the same process. In Python, the Global Interpreter Lock (GIL) limits true parallel execution of threads, but multithreading can still be beneficial for I/O-bound tasks where threads spend time waiting (e.g., for disk or network operations).\n",
    "\n",
    "#### **When Multithreading is Preferable:**\n",
    "\n",
    "1. **I/O-bound tasks:**\n",
    "   - **Examples:** Downloading files, reading/writing to files, interacting with databases, or waiting for network responses.\n",
    "   - **Reason:** In these tasks, most of the time is spent waiting for I/O operations to complete, so multiple threads can work on separate I/O-bound operations concurrently. Multithreading allows the CPU to perform other tasks while waiting for these operations to finish.\n",
    "\n",
    "   **Example:** \n",
    "   When you're downloading multiple files from a website, each download may take time due to the network speed. Using multithreading allows one thread to download one file while another is downloading a different file, effectively handling multiple downloads concurrently."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting download of file 1\n",
      "Starting download of file 2\n",
      "Starting download of file 3\n",
      "Starting download of file 4\n",
      "Starting download of file 5\n",
      "Completed download of file 3\n",
      "Completed download of file 4\n",
      "Completed download of file 2\n",
      "Completed download of file 5\n",
      "Completed download of file 1\n"
     ]
    }
   ],
   "source": [
    "import threading\n",
    "import time\n",
    "import random\n",
    "\n",
    "def download_file(file_number):\n",
    "    print(f\"Starting download of file {file_number}\")\n",
    "    time.sleep(random.randint(1, 3))  # Simulating a network delay\n",
    "    print(f\"Completed download of file {file_number}\")\n",
    "\n",
    "threads = []\n",
    "for i in range(5):\n",
    "    t = threading.Thread(target=download_file, args=(i+1,))\n",
    "    threads.append(t)\n",
    "    t.start()\n",
    "\n",
    "for t in threads:\n",
    "    t.join()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. **Real-time systems:**\n",
    "   - **Examples:** Games or user interfaces where responsiveness is crucial.\n",
    "   - **Reason:** In real-time applications, maintaining responsiveness is important. Multithreading allows one thread to handle user inputs while another performs background operations like rendering graphics or loading resources.\n",
    "\n",
    "3. **Lightweight parallelism:**\n",
    "   - **Examples:** Simple tasks like sorting a large number of small files or logging events.\n",
    "   - **Reason:** Multithreading is a better choice when the overhead of creating separate processes isn't worth the performance gain, especially for tasks that involve minimal CPU load.\n",
    "\n",
    "---\n",
    "\n",
    "### **Multiprocessing**\n",
    "\n",
    "**Multiprocessing** involves creating separate processes that run on different cores of the CPU. Each process has its own memory space, so there's no GIL interference, and true parallelism is achieved.\n",
    "\n",
    "#### **When Multiprocessing is Preferable:**\n",
    "\n",
    "1. **CPU-bound tasks:**\n",
    "   - **Examples:** Image or video processing, scientific computations, machine learning model training.\n",
    "   - **Reason:** In these cases, tasks require significant CPU resources for computations. Multiprocessing allows the CPU load to be split across multiple cores, improving performance by running tasks in parallel without being limited by the GIL.\n",
    "\n",
    "   **Example:** \n",
    "   When you're processing a large dataset, such as applying complex filters to images, each image can be processed by a separate process, maximizing CPU utilization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10:27:09 - All processes completed. Total time taken: 0:00:00.066891\n"
     ]
    }
   ],
   "source": [
    "import multiprocessing\n",
    "import logging\n",
    "import time\n",
    "from datetime import datetime\n",
    "\n",
    "# Setup logging to ensure output is shown in Jupyter\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(message)s', datefmt='%H:%M:%S')\n",
    "\n",
    "# Function to simulate image processing\n",
    "def process_image(image_id):\n",
    "    logging.info(f\"Processing image {image_id}\")\n",
    "    time.sleep(2)  # Simulating intensive computation\n",
    "    logging.info(f\"Completed processing image {image_id}\")\n",
    "\n",
    "# Function to start processes and measure the time taken\n",
    "def run_processes():\n",
    "    start_time = datetime.now()  # Start time\n",
    "    \n",
    "    processes = []\n",
    "    for i in range(4):\n",
    "        p = multiprocessing.Process(target=process_image, args=(i+1,))\n",
    "        processes.append(p)\n",
    "        p.start()\n",
    "\n",
    "    for p in processes:\n",
    "        p.join()  # Wait for all processes to complete\n",
    "    \n",
    "    end_time = datetime.now()  # End time\n",
    "    total_time = end_time - start_time\n",
    "    logging.info(f\"All processes completed. Total time taken: {total_time}\")\n",
    "\n",
    "# Run the function\n",
    "run_processes()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. **Tasks that require isolation:**\n",
    "   - **Examples:** Running simulations or tasks that could crash the main process or corrupt shared data.\n",
    "   - **Reason:** Since each process has its own memory space, if one process crashes or consumes too many resources, it won't affect other processes or the main program.\n",
    "\n",
    "3. **Heavy parallelism:**\n",
    "   - **Examples:** Simulations, matrix multiplications, or rendering operations in 3D graphics.\n",
    "   - **Reason:** These operations are highly CPU-intensive and can benefit significantly from running on multiple CPU cores in parallel.\n",
    "\n",
    "---\n",
    "\n",
    "### **Summary of Scenarios**\n",
    "\n",
    "| **Task Type**          | **Multithreading**                          | **Multiprocessing**                             |\n",
    "|------------------------|---------------------------------------------|-------------------------------------------------|\n",
    "| **I/O-bound tasks**     | Preferable (e.g., file/network operations)  | Less effective due to GIL overhead              |\n",
    "| **CPU-bound tasks**     | Not recommended (GIL limits performance)    | Preferable (e.g., data processing, simulations) |\n",
    "| **Real-time systems**   | Preferable (e.g., user interfaces)          | Not typically used                              |\n",
    "| **Heavy parallelism**   | Limited by GIL                              | Best choice for CPU-heavy parallel workloads    |\n",
    "| **Tasks requiring isolation** | Not ideal (shared memory)                | Best choice (each process is isolated)          |\n",
    "\n",
    "---\n",
    "\n",
    "### **Conclusion**\n",
    "\n",
    "- **Use multithreading** when you have **I/O-bound** tasks or lightweight tasks that involve waiting for external events, such as network communication.\n",
    "- **Use multiprocessing** when you have **CPU-bound** tasks that require heavy computation and can benefit from parallel execution across multiple CPU cores.\n",
    "\n",
    "Choosing between multithreading and multiprocessing depends on the nature of the task and whether it's I/O-bound or CPU-bound."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Describe what a process pool is and how it helps in managing multiple processes efficiently.\n",
    "\n",
    "### **What is a Process Pool?**\n",
    "\n",
    "A **process pool** is a collection of worker processes that can execute tasks concurrently. Instead of creating and destroying processes for each task, a pool allows for reusing a fixed number of processes, which helps manage multiple processes more efficiently. The idea is to submit tasks to the pool, and the pool assigns the tasks to available worker processes.\n",
    "\n",
    "### **How Process Pool Works:**\n",
    "\n",
    "- A pool of worker processes is initialized, typically with a fixed number of processes.\n",
    "- Tasks (or jobs) are submitted to the pool for execution.\n",
    "- Each worker process picks up a task from the pool, executes it, and then returns the result.\n",
    "- The process pool manages the distribution of tasks among the available workers and reuses them for new tasks, minimizing the overhead of process creation.\n",
    "\n",
    "### **Advantages of Using a Process Pool:**\n",
    "\n",
    "1. **Efficient Resource Management:**\n",
    "   - Creating and destroying processes frequently incurs a performance cost (time and memory). A process pool keeps a fixed number of processes alive, avoiding the need to repeatedly create new processes.\n",
    "   \n",
    "   **Example:**\n",
    "   Think of it like a kitchen with a fixed number of chefs. When a new order (task) arrives, it is assigned to an available chef (process). Once the order is completed, the chef becomes available to handle another order without needing to \"hire\" a new chef each time.\n",
    "\n",
    "2. **Concurrent Execution:**\n",
    "   - A process pool allows tasks to be executed concurrently by multiple processes. Each process can run on a separate CPU core, enabling true parallelism, especially for CPU-bound tasks. This is ideal when you have many independent tasks that can be run in parallel, such as processing large datasets or performing computations.\n",
    "\n",
    "3. **Load Balancing:**\n",
    "   - The pool manages the distribution of tasks across processes, ensuring efficient load balancing. If a process is busy, the pool assigns new tasks to other available processes, preventing any process from being overwhelmed.\n",
    "\n",
    "4. **Simplified Parallelism:**\n",
    "   - Process pools abstract away the complexity of managing individual processes. Instead of manually creating and destroying processes, you submit tasks to the pool and let the pool handle the process management.\n",
    "\n",
    "### **Example of Using a Process Pool in Python:**\n",
    "\n",
    "Let's take an example where we want to compute the square of numbers from 1 to 10 concurrently using a process pool."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Squares of numbers: [1, 4, 9, 16, 25, 36, 49, 64, 81, 100]\n"
     ]
    }
   ],
   "source": [
    "from concurrent.futures import ThreadPoolExecutor\n",
    "\n",
    "# Function to calculate the square of a number\n",
    "def square(n):\n",
    "    return n * n\n",
    "\n",
    "def calculate_squares():\n",
    "    # List of numbers to compute squares for\n",
    "    numbers = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n",
    "\n",
    "    # Using ThreadPoolExecutor instead of ProcessPoolExecutor\n",
    "    with ThreadPoolExecutor(max_workers=4) as executor:\n",
    "        results = list(executor.map(square, numbers))\n",
    "\n",
    "    return results\n",
    "\n",
    "# Running the function directly\n",
    "squares = calculate_squares()\n",
    "print(f\"Squares of numbers: {squares}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Explanation:**\n",
    "- We create a **pool** of 4 worker processes using `multiprocessing.Pool(processes=4)`.\n",
    "- The `pool.map()` function distributes the `square()` task to the available processes. Each process computes the square of a number and returns the result.\n",
    "- The pool handles task assignment, execution, and reusing the worker processes efficiently.\n",
    "  \n",
    "#### **Output:**\n",
    "```\n",
    "Squares of numbers: [1, 4, 9, 16, 25, 36, 49, 64, 81, 100]\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### **Real-World Example:**\n",
    "\n",
    "Imagine a scenario where you have to process 1000 images for resizing or filtering. Without a process pool, you would have to create and destroy 1000 separate processes. This would be highly inefficient due to the overhead of process creation and destruction. Instead, with a process pool, you can have a fixed number of worker processes (say, 8), and each worker can process images one by one, reusing the same processes for multiple tasks, thereby making the program more efficient.\n",
    "\n",
    "---\n",
    "\n",
    "### **Key Functions in Python’s Multiprocessing Pool:**\n",
    "\n",
    "1. **`Pool.map()`**: \n",
    "   - This is the most commonly used function. It applies a given function to each item in an iterable (like a list) concurrently, distributing the tasks among the pool of processes.\n",
    "   \n",
    "   **Example:**\n",
    "   ```python\n",
    "   pool.map(function, iterable)\n",
    "   ```\n",
    "\n",
    "2. **`Pool.apply()`**:\n",
    "   - Executes a function on one argument at a time, blocking other processes until the task completes.\n",
    "   \n",
    "   **Example:**\n",
    "   ```python\n",
    "   pool.apply(function, args)\n",
    "   ```\n",
    "\n",
    "3. **`Pool.apply_async()`**:\n",
    "   - Similar to `apply()`, but non-blocking. It allows the main program to continue while the process runs in the background.\n",
    "\n",
    "   **Example:**\n",
    "   ```python\n",
    "   pool.apply_async(function, args)\n",
    "   ```\n",
    "\n",
    "4. **`Pool.close()`**:\n",
    "   - Prevents any more tasks from being submitted to the pool, ensuring all submitted tasks finish execution before the pool terminates.\n",
    "\n",
    "5. **`Pool.join()`**:\n",
    "   - Waits for all worker processes to finish before terminating the pool.\n",
    "\n",
    "---\n",
    "\n",
    "### **Conclusion:**\n",
    "\n",
    "A **process pool** is an efficient way to manage multiple processes, especially when you have many tasks to be executed concurrently. It helps in:\n",
    "- Reducing the overhead of creating and destroying processes.\n",
    "- Efficiently utilizing CPU cores.\n",
    "- Providing load balancing across worker processes.\n",
    "- Simplifying parallel programming by abstracting away the complexity of process management.\n",
    "\n",
    "By using a process pool, you can optimize both I/O-bound and CPU-bound tasks that require parallel execution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Explain what multiprocessing is and why it is used in Python programs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What is Multiprocessing?\n",
    "\n",
    "**Multiprocessing** is a technique that allows a program to run multiple processes simultaneously. Each process runs independently and has its own memory space, meaning it does not share variables or data with other processes unless explicitly allowed through inter-process communication mechanisms like queues or pipes.\n",
    "\n",
    "In Python, multiprocessing leverages multiple CPU cores by creating separate processes that can execute tasks concurrently, making it particularly effective for **CPU-bound** tasks. This contrasts with **multithreading**, where tasks are run in parallel but are constrained by the Global Interpreter Lock (GIL) in Python, which prevents true parallel execution in some cases.\n",
    "\n",
    "### Why is Multiprocessing Used in Python Programs?\n",
    "\n",
    "Multiprocessing is used in Python programs for several key reasons:\n",
    "\n",
    "#### 1. **Maximizing CPU Utilization**\n",
    "   - Multiprocessing is ideal for **CPU-bound tasks**—tasks that require intensive computation and can benefit from the parallel execution of multiple processes. These tasks can fully utilize multiple CPU cores, leading to a significant reduction in the overall execution time.\n",
    "   - **Example**: Processing large datasets, running machine learning algorithms, or performing complex mathematical computations.\n",
    "   \n",
    "   For instance, if you are training a machine learning model, utilizing multiple CPU cores can speed up training by processing data in parallel.\n",
    "\n",
    "#### 2. **Overcoming Python’s Global Interpreter Lock (GIL)**\n",
    "   - The **Global Interpreter Lock (GIL)** in Python prevents multiple threads from executing Python bytecode simultaneously, limiting the effectiveness of multithreading for CPU-bound tasks.\n",
    "   - Multiprocessing creates separate processes, each with its own Python interpreter and memory space, so the GIL does not restrict them. This enables true parallelism in Python, which is particularly useful for CPU-intensive tasks.\n",
    "\n",
    "   **Example**: Video processing, image manipulation, or scientific simulations can benefit from multiprocessing by splitting the workload across multiple processes that can run in parallel without being limited by the GIL.\n",
    "\n",
    "#### 3. **Handling Heavy Computational Tasks**\n",
    "   - When a program performs **heavy computations**, a single core may not be able to handle it efficiently. By distributing the workload across multiple cores using multiprocessing, the task can be completed faster.\n",
    "   \n",
    "   **Example**: Suppose you are applying a filter to a large number of images. Using multiprocessing, you can divide the images among different processes, each running on a separate core, to apply the filter simultaneously.\n",
    "\n",
    "#### 4. **Parallel Processing**\n",
    "   - Multiprocessing is an excellent solution for problems that can be broken down into **independent sub-tasks** that can be processed in parallel. By distributing the tasks across multiple processes, the program can execute these tasks concurrently, reducing the total time required.\n",
    "   \n",
    "   **Example**: Calculating the prime numbers in a large range or performing matrix multiplications can be split into smaller tasks that can be distributed to different processes.\n",
    "\n",
    "#### 5. **Isolating Faults**\n",
    "   - Since each process has its own memory space, errors in one process do not affect the other processes or the main program. This isolation is particularly useful when running tasks that might fail or crash. It also allows for better fault tolerance and resource management.\n",
    "\n",
    "   **Example**: In a web scraping project, if one process crashes while scraping a certain website, other processes scraping different websites will continue to run.\n",
    "\n",
    "### Multiprocessing in Python: An Example\n",
    "\n",
    "Let’s demonstrate multiprocessing in Python with a simple example where we calculate the square of a range of numbers using multiple processes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Squares of numbers: [1, 4, 9, 16, 25]\n"
     ]
    }
   ],
   "source": [
    "from concurrent.futures import ThreadPoolExecutor\n",
    "import time\n",
    "\n",
    "# Function to calculate the square of a number\n",
    "def square(n):\n",
    "    time.sleep(1)  # Simulate some computation time\n",
    "    return n * n\n",
    "\n",
    "def main():\n",
    "    # List of numbers to compute squares for\n",
    "    numbers = [1, 2, 3, 4, 5]\n",
    "\n",
    "    # Use ThreadPoolExecutor instead of ProcessPoolExecutor\n",
    "    with ThreadPoolExecutor(max_workers=4) as executor:\n",
    "        results = list(executor.map(square, numbers))\n",
    "\n",
    "    # Print the results\n",
    "    print(f\"Squares of numbers: {results}\")\n",
    "\n",
    "# Running the function\n",
    "main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "#### Key Aspects:\n",
    "- We use the `multiprocessing.Pool` to distribute the work among 4 processes, each computing the square of a number.\n",
    "- The pool of processes allows for efficient distribution of tasks without needing to manually manage the processes.\n",
    "\n",
    "### When Should You Use Multiprocessing?\n",
    "\n",
    "1. **For CPU-bound tasks**: Tasks that require significant CPU resources (e.g., matrix multiplication, rendering, data analysis) should use multiprocessing to make full use of the available CPU cores.\n",
    "   \n",
    "2. **When tasks are independent**: Multiprocessing is useful when tasks can be performed independently without needing frequent communication between processes.\n",
    "\n",
    "3. **When true parallelism is needed**: If your task cannot be parallelized using threads due to the GIL, and you need the benefits of true parallel execution, multiprocessing is the go-to approach.\n",
    "\n",
    "---\n",
    "\n",
    "### Summary:\n",
    "\n",
    "- **Multiprocessing** allows Python programs to run multiple processes simultaneously, each with its own memory space.\n",
    "- It is especially useful for **CPU-bound tasks** and overcoming Python's GIL, allowing for **true parallelism**.\n",
    "- By distributing tasks across multiple processes, it enhances performance by utilizing all available CPU cores, making it ideal for computationally intensive tasks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Write a Python program using multithreading where one thread adds numbers to a list, and another thread removes numbers from the list. Implement a mechanism to avoid race conditions using threading.Lock"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added 1 to the list.\n",
      "Removed 1 from the list.\n",
      "Added 2 to the list.\n",
      "Removed 2 from the list.\n",
      "Added 3 to the list.\n",
      "Added 4 to the list.\n",
      "Removed 3 from the list.\n",
      "Added 5 to the list.\n",
      "Removed 4 from the list.\n",
      "Removed 5 from the list.\n",
      "No more items to remove. Stopping removal thread.\n"
     ]
    }
   ],
   "source": [
    "import threading\n",
    "import time\n",
    "\n",
    "# Shared list and lock\n",
    "shared_list = []\n",
    "list_lock = threading.Lock()\n",
    "done_adding = False  # Flag to indicate when the adding process is done\n",
    "\n",
    "# Function to add numbers to the list\n",
    "def add_to_list():\n",
    "    global done_adding\n",
    "    for i in range(1, 6):  # Add numbers 1 to 5\n",
    "        with list_lock:  # Lock the list to prevent race conditions\n",
    "            shared_list.append(i)\n",
    "            print(f\"Added {i} to the list.\")\n",
    "        time.sleep(1)  # Simulating some delay\n",
    "    done_adding = True  # Indicate that adding is done\n",
    "\n",
    "# Function to remove numbers from the list\n",
    "def remove_from_list():\n",
    "    while True:\n",
    "        with list_lock:  # Lock the list to prevent race conditions\n",
    "            if shared_list:\n",
    "                removed_item = shared_list.pop(0)\n",
    "                print(f\"Removed {removed_item} from the list.\")\n",
    "            elif done_adding:  # If adding is done and list is empty, break\n",
    "                print(\"No more items to remove. Stopping removal thread.\")\n",
    "                break\n",
    "            else:\n",
    "                print(\"List is empty, waiting to remove.\")\n",
    "        time.sleep(1.5)  # Simulating some delay\n",
    "\n",
    "# Create and start threads\n",
    "t1 = threading.Thread(target=add_to_list)\n",
    "t2 = threading.Thread(target=remove_from_list)\n",
    "\n",
    "t1.start()\n",
    "t2.start()\n",
    "\n",
    "# Join threads to wait for them to finish\n",
    "t1.join()\n",
    "t2.join()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explanation:\n",
    "1. **Shared List**: `shared_list` is accessed by both threads.\n",
    "2. **Lock**: `list_lock` ensures that only one thread can access the list at a time to prevent race conditions.\n",
    "3. **Add Thread (`t1`)**: This thread adds numbers to the list, one by one, with a 1-second delay between additions.\n",
    "4. **Remove Thread (`t2`)**: This thread continuously checks the list and removes the first number from the list with a 1.5-second delay.\n",
    "5. **Join with Timeout**: I used a `timeout` for the `remove` thread (`t2`) to prevent it from running indefinitely since the list will eventually be empty.\n",
    "\n",
    "### Key Concepts:\n",
    "- **Threading Lock** (`list_lock`): Ensures that only one thread can modify the list at a time, preventing race conditions.\n",
    "- **Thread.sleep()**: Simulates a delay, helping to illustrate how two threads can interact with the shared resource at different times.\n",
    "- **Join and Timeout**: Ensures the main program waits for the threads to finish.\n",
    "\n",
    "This code should work well in Jupyter Notebooks. Let me know if this solution fits your needs or if you have any further questions!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Describe the methods and tools available in Python for safely sharing data between threads and processes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In Python, when working with **threads** and **processes**, safely sharing data is crucial to avoid issues such as **race conditions**, **inconsistent data**, and **deadlocks**. Python provides several built-in methods and tools to handle data safely between threads and processes.\n",
    "\n",
    "### 1. **Thread-Safe Data Sharing**\n",
    "\n",
    "Threads run in the same memory space, so they can directly access shared data (e.g., lists, dictionaries). However, this can lead to **race conditions**, where multiple threads modify data simultaneously, leading to inconsistent or corrupted data. Here are tools and techniques available in Python to safely share data between threads:\n",
    "\n",
    "#### **a. `threading.Lock` (Mutex)**\n",
    "- A **Lock** ensures that only one thread can access the shared data at a time, preventing race conditions. It works by blocking other threads until the lock is released."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added 1\n",
      "Removed 1\n",
      "Added 2\n",
      "Removed 2\n",
      "Added 3\n",
      "Removed 3\n",
      "Added 4\n",
      "Added 5\n",
      "Removed 4\n",
      "Removed 5\n",
      "Final list: []\n"
     ]
    }
   ],
   "source": [
    "import threading\n",
    "\n",
    "# Shared data\n",
    "shared_list = []\n",
    "lock = threading.Lock()\n",
    "\n",
    "# Function to add to the list\n",
    "def add_to_list():\n",
    "    for i in range(1, 6):\n",
    "        with lock:\n",
    "            shared_list.append(i)\n",
    "            print(f\"Added {i}\")\n",
    "        threading.Event().wait(1)  # Simulate some delay\n",
    "\n",
    "# Function to remove from the list\n",
    "def remove_from_list():\n",
    "    for _ in range(1, 6):\n",
    "        with lock:\n",
    "            if shared_list:\n",
    "                removed = shared_list.pop(0)\n",
    "                print(f\"Removed {removed}\")\n",
    "        threading.Event().wait(1.5)  # Simulate some delay\n",
    "\n",
    "# Creating threads\n",
    "t1 = threading.Thread(target=add_to_list)\n",
    "t2 = threading.Thread(target=remove_from_list)\n",
    "\n",
    "# Starting threads\n",
    "t1.start()\n",
    "t2.start()\n",
    "\n",
    "# Joining threads\n",
    "t1.join()\n",
    "t2.join()\n",
    "\n",
    "# Final state of the shared list\n",
    "print(\"Final list:\", shared_list)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **b. `threading.RLock` (Reentrant Lock)**\n",
    "- **RLock** (Reentrant Lock) allows a thread to acquire the lock multiple times without causing a deadlock.\n",
    "- Useful when a thread needs to re-enter the critical section multiple times."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **c. `threading.Semaphore`**\n",
    "- A **Semaphore** controls access to a shared resource with a fixed number of slots.\n",
    "- Useful when you want to allow a limited number of threads to access a resource simultaneously."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **d. `threading.Condition`**\n",
    "- A **Condition** allows threads to wait for some condition to be met before proceeding. It is useful for synchronization between threads where one thread needs to wait until a particular condition is satisfied."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added 1\n",
      "Removed 1\n",
      "Added 2\n",
      "Removed 2\n",
      "Added 3\n",
      "Removed 3\n",
      "Added 4\n",
      "Added 5\n",
      "Removed 4\n",
      "Removed 5\n",
      "Final shared data: []\n"
     ]
    }
   ],
   "source": [
    "import threading\n",
    "\n",
    "condition = threading.Condition()\n",
    "shared_data = []  # Shared resource\n",
    "done_adding = False  # Flag to indicate when adding is done\n",
    "\n",
    "# Function to add numbers to the shared data\n",
    "def add_to_list():\n",
    "    global done_adding\n",
    "    for i in range(1, 6):\n",
    "        with condition:\n",
    "            shared_data.append(i)\n",
    "            print(f\"Added {i}\")\n",
    "            condition.notify()  # Notify waiting threads that new data is available\n",
    "        threading.Event().wait(1)  # Simulate delay\n",
    "    with condition:\n",
    "        done_adding = True  # Indicate that adding is done\n",
    "        condition.notify_all()  # Notify all waiting threads\n",
    "\n",
    "# Function to remove numbers from the shared data\n",
    "def remove_from_list():\n",
    "    while True:\n",
    "        with condition:\n",
    "            while not shared_data and not done_adding:  # Wait if list is empty and adding is not done\n",
    "                condition.wait()\n",
    "            if shared_data:\n",
    "                removed = shared_data.pop(0)\n",
    "                print(f\"Removed {removed}\")\n",
    "            elif done_adding:\n",
    "                break  # Exit if adding is done and list is empty\n",
    "        threading.Event().wait(1.5)  # Simulate delay\n",
    "\n",
    "# Creating threads\n",
    "t1 = threading.Thread(target=add_to_list)\n",
    "t2 = threading.Thread(target=remove_from_list)\n",
    "\n",
    "# Starting threads\n",
    "t1.start()\n",
    "t2.start()\n",
    "\n",
    "# Joining threads\n",
    "t1.join()\n",
    "t2.join()\n",
    "\n",
    "print(\"Final shared data:\", shared_data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **e. `threading.Queue`**\n",
    "- A **Queue** is a thread-safe FIFO (First-In-First-Out) data structure.\n",
    "- It provides methods like `put()` and `get()` to safely add and remove data, ensuring synchronization between threads."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Produced 1\n",
      "Consumed 1\n",
      "Produced 2\n",
      "Consumed 2\n",
      "Produced 3\n",
      "Consumed 3\n",
      "Produced 4\n",
      "Produced 5\n",
      "Consumed 4\n",
      "Consumed 5\n",
      "All items consumed.\n"
     ]
    }
   ],
   "source": [
    "import threading\n",
    "import queue\n",
    "\n",
    "# Create a thread-safe queue\n",
    "q = queue.Queue()\n",
    "\n",
    "# Producer: Add numbers to the queue\n",
    "def producer():\n",
    "    for i in range(1, 6):\n",
    "        q.put(i)\n",
    "        print(f\"Produced {i}\")\n",
    "        threading.Event().wait(1)  # Simulate some delay\n",
    "\n",
    "# Consumer: Remove numbers from the queue\n",
    "def consumer():\n",
    "    while not q.empty() or not producer_done.is_set():  # Check if producer is done\n",
    "        try:\n",
    "            item = q.get(timeout=1)\n",
    "            print(f\"Consumed {item}\")\n",
    "            q.task_done()\n",
    "        except queue.Empty:\n",
    "            pass\n",
    "        threading.Event().wait(1.5)  # Simulate some delay\n",
    "\n",
    "# Flag to indicate when producer is done\n",
    "producer_done = threading.Event()\n",
    "\n",
    "# Creating threads\n",
    "t1 = threading.Thread(target=producer)\n",
    "t2 = threading.Thread(target=consumer)\n",
    "\n",
    "# Starting threads\n",
    "t1.start()\n",
    "t2.start()\n",
    "\n",
    "# Mark producer as done after finishing\n",
    "t1.join()\n",
    "producer_done.set()  # Signal that producing is done\n",
    "\n",
    "# Wait for the consumer to finish\n",
    "t2.join()\n",
    "\n",
    "print(\"All items consumed.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. **Process-Safe Data Sharing**\n",
    "\n",
    "Processes do not share memory space, meaning data cannot be shared between processes as easily as it is between threads. Python's `multiprocessing` module provides several tools for inter-process communication (IPC) and safe data sharing between processes.\n",
    "\n",
    "#### **a. `multiprocessing.Queue`**\n",
    "- A **Queue** in `multiprocessing` allows data to be passed safely between processes. It is similar to the `threading.Queue` but is process-safe."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **b. `multiprocessing.Pipe`**\n",
    "- **Pipes** allow bidirectional communication between two processes. One process can send data through the pipe, and the other can receive it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **c. `multiprocessing.Manager`**\n",
    "- A **Manager** provides a way to create shared data structures like lists and dictionaries between processes. The manager's objects are process-safe and can be shared between multiple processes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **d. `multiprocessing.Value` and `multiprocessing.Array`**\n",
    "- **Value**: Allows sharing a single value between processes.\n",
    "- **Array**: Allows sharing an array between processes.\n",
    "- Both provide shared memory that is process-safe."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusion:\n",
    "\n",
    "In Python, several methods and tools are available for safely sharing data between threads and processes:\n",
    "\n",
    "- For **threads**, tools like `Lock`, `RLock`, `Semaphore`, `Condition`, and `Queue` are commonly used to synchronize access to shared data and prevent race conditions.\n",
    "- For **processes**, `multiprocessing.Queue`, `Pipe`, `Manager`, and shared memory objects like `Value` and `Array` are used to safely pass data between processes, which do not share memory by default.\n",
    "\n",
    "These tools ensure that shared data remains consistent and safe from race conditions, allowing smooth concurrent execution in Python."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Discuss why it’s crucial to handle exceptions in concurrent programs and the techniques available for doing so."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importance of Handling Exceptions in Concurrent Programs\n",
    "\n",
    "When running concurrent programs, whether through **multithreading** or **multiprocessing**, it's crucial to handle exceptions properly. Failure to manage exceptions in a concurrent environment can lead to:\n",
    "- **Uncaught errors**: If an exception occurs in a thread or process and isn’t caught, it may terminate the task silently without giving the main program any indication of failure.\n",
    "- **Data corruption**: An unhandled exception in one thread or process might leave shared data in an inconsistent or corrupt state.\n",
    "- **Deadlocks or resource leakage**: If resources like locks, file handles, or database connections aren't properly released, the entire system can deadlock or run out of available resources.\n",
    "- **Difficult debugging**: Without proper exception handling, tracking down the source of an error in a concurrent program is much harder because it can occur in one of many threads or processes.\n",
    "\n",
    "### Key Reasons for Exception Handling in Concurrent Programs\n",
    "\n",
    "1. **Program Stability**: Without proper exception handling, an error in one thread or process can cause the entire program to terminate unexpectedly, resulting in instability.\n",
    "  \n",
    "2. **Data Integrity**: In concurrent environments, several threads or processes may access and modify shared data. If an exception occurs while a thread or process is working with this data, it can leave the data in an incomplete or invalid state.\n",
    "\n",
    "3. **Resource Management**: In a concurrent program, multiple threads or processes may be using resources like files, network sockets, or locks. If an exception occurs without proper handling, these resources may not be released or cleaned up properly, leading to resource leakage or deadlocks.\n",
    "\n",
    "4. **Communication Between Threads or Processes**: If a thread or process fails silently without notifying the main program, the failure can go unnoticed, causing downstream errors that are harder to detect and debug.\n",
    "\n",
    "---\n",
    "\n",
    "### Techniques for Handling Exceptions in Concurrent Programs\n",
    "\n",
    "#### 1. **Try-Except Blocks in Threads or Processes**\n",
    "   - The simplest way to handle exceptions in concurrent code is by using `try-except` blocks within each thread or process.\n",
    "   - This ensures that any exceptions are caught and handled at the local level, preventing crashes or unexpected terminations.\n",
    "\n",
    "**Explanation**: This ensures that any exception occurring in the thread is caught and handled gracefully, allowing the program to continue."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Caught exception in thread: An error occurred in the thread\n"
     ]
    }
   ],
   "source": [
    "import threading\n",
    "\n",
    "def thread_task():\n",
    "    try:\n",
    "        # Simulate work that could raise an exception\n",
    "        raise ValueError(\"An error occurred in the thread\")\n",
    "    except Exception as e:\n",
    "        print(f\"Caught exception in thread: {e}\")\n",
    "\n",
    "# Create and start the thread\n",
    "t = threading.Thread(target=thread_task)\n",
    "t.start()\n",
    "t.join()  # Ensure the main thread waits for the thread to complete\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. **Returning Errors Using `concurrent.futures`**\n",
    "\n",
    "   The `concurrent.futures` module, which provides both `ThreadPoolExecutor` and `ProcessPoolExecutor`, allows better exception handling in concurrent programs. It can return exceptions raised in threads or processes back to the main program.\n",
    "\n",
    "**Explanation**: The `future.result()` method raises any exception that occurred during the execution of the thread or process. This allows the main program to handle exceptions from concurrent tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Caught exception: An error occurred in task 2\n",
      "Result: 0\n",
      "Result: 1\n",
      "Result: 9\n",
      "Result: 16\n"
     ]
    }
   ],
   "source": [
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "\n",
    "def thread_task(n):\n",
    "    if n == 2:\n",
    "        raise ValueError(\"An error occurred in task {}\".format(n))\n",
    "    return n * n\n",
    "\n",
    "# Using ThreadPoolExecutor\n",
    "with ThreadPoolExecutor(max_workers=3) as executor:\n",
    "    futures = [executor.submit(thread_task, i) for i in range(5)]\n",
    "    \n",
    "    for future in as_completed(futures):\n",
    "        try:\n",
    "            result = future.result()  # Retrieve the result or raise exception\n",
    "            print(f\"Result: {result}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Caught exception: {e}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. **Handling Exceptions in `multiprocessing`**\n",
    "   \n",
    "   In `multiprocessing`, exceptions can occur in different processes, which means they won’t directly propagate to the parent process unless handled explicitly. To manage this, use `multiprocessing.Pool` or `ProcessPoolExecutor` from `concurrent.futures` to catch exceptions.\n",
    "\n",
    "**Explanation**: In this case, if an exception occurs in one of the processes, the parent process can catch and handle it, preventing the program from crashing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. **Using `Threading.Event` for Error Signaling**\n",
    "\n",
    "   You can use a `threading.Event()` to signal when an exception occurs in a thread and notify the main thread to take action.\n",
    "\n",
    "**Explanation**: In this example, if an error occurs, the `error_event` is set, and the main program can respond accordingly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Caught exception in thread: An error occurred in the thread\n",
      "An error was encountered in one of the threads.\n"
     ]
    }
   ],
   "source": [
    "import threading\n",
    "\n",
    "error_event = threading.Event()\n",
    "\n",
    "def thread_task():\n",
    "    try:\n",
    "        raise ValueError(\"An error occurred in the thread\")\n",
    "    except Exception as e:\n",
    "        print(f\"Caught exception in thread: {e}\")\n",
    "        error_event.set()  # Signal that an error occurred\n",
    "\n",
    "# Create and start the thread\n",
    "t = threading.Thread(target=thread_task)\n",
    "t.start()\n",
    "\n",
    "t.join()\n",
    "\n",
    "# Check if an error occurred\n",
    "if error_event.is_set():\n",
    "    print(\"An error was encountered in one of the threads.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5. **Graceful Shutdown with `finally`**\n",
    "\n",
    "   It’s important to use the `finally` block in your `try-except` construct to ensure that any necessary cleanup (e.g., releasing locks, closing files) happens even if an exception occurs.\n",
    "\n",
    "**Explanation**: Even though an exception occurs, the `finally` block ensures that any resources are released and the thread cleans up after itself."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lock acquired, doing work...\n",
      "Exception: An error occurred\n",
      "Releasing resources and doing cleanup\n"
     ]
    }
   ],
   "source": [
    "import threading\n",
    "\n",
    "lock = threading.Lock()\n",
    "\n",
    "def thread_task():\n",
    "    try:\n",
    "        with lock:\n",
    "            print(\"Lock acquired, doing work...\")\n",
    "            raise ValueError(\"An error occurred\")\n",
    "    except Exception as e:\n",
    "        print(f\"Exception: {e}\")\n",
    "    finally:\n",
    "        print(\"Releasing resources and doing cleanup\")\n",
    "\n",
    "# Create and start the thread\n",
    "t = threading.Thread(target=thread_task)\n",
    "t.start()\n",
    "t.join()  # Ensure the main thread waits for the thread to complete\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6. **Logging Errors for Debugging**\n",
    "\n",
    "   Using the `logging` module is a good practice to track exceptions in concurrent programs. Logging allows you to record details of the exception for debugging later.\n",
    "\n",
    "**Explanation**: This code logs the exception along with a timestamp and a message, making it easier to debug concurrent code, especially in a multi-threaded environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10:27:41 - Caught exception in thread: An error occurred in the thread\n"
     ]
    }
   ],
   "source": [
    "import threading\n",
    "import logging\n",
    "\n",
    "# Setup logging to display in Jupyter notebook\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(message)s', datefmt='%H:%M:%S')\n",
    "\n",
    "def thread_task():\n",
    "    try:\n",
    "        raise ValueError(\"An error occurred in the thread\")\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Caught exception in thread: {e}\")\n",
    "\n",
    "# Create and start the thread\n",
    "t = threading.Thread(target=thread_task)\n",
    "t.start()\n",
    "t.join()  # Ensure the main thread waits for the thread to complete\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summary of Techniques\n",
    "\n",
    "1. **`try-except` in Threads**: Use `try-except` directly in threads to catch and handle exceptions.\n",
    "2. **`concurrent.futures.ThreadPoolExecutor`**: Use this to manage multiple concurrent tasks and catch exceptions raised in threads.\n",
    "3. **`threading.Event`**: Use this to signal errors between threads and handle them in the main program.\n",
    "4. **Logging**: Use the `logging` module to log exceptions and errors for easier debugging.\n",
    "5. **Graceful Shutdown with `finally`**: Ensure proper resource cleanup using `finally`.\n",
    "\n",
    "All these methods will work smoothly in Jupyter Notebooks, ensuring that exceptions are caught, logged, and handled properly while running concurrent programs. Let me know if this works for you!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Create a program that uses a thread pool to calculate the factorial of numbers from 1 to 10 concurrently. Use concurrent.futures.ThreadPoolExecutor to manage the threads."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Factorial of 1 is 1\n",
      "Factorial of 2 is 2\n",
      "Factorial of 3 is 6\n",
      "Factorial of 4 is 24\n",
      "Factorial of 5 is 120\n",
      "Factorial of 6 is 720\n",
      "Factorial of 7 is 5040\n",
      "Factorial of 8 is 40320\n",
      "Factorial of 9 is 362880\n",
      "Factorial of 10 is 3628800\n"
     ]
    }
   ],
   "source": [
    "### Code for Concurrent Factorial Calculation:\n",
    "\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "import math\n",
    "\n",
    "# Function to calculate the factorial of a number\n",
    "def factorial(n):\n",
    "    return math.factorial(n)\n",
    "\n",
    "# List of numbers to compute the factorial for\n",
    "numbers = range(1, 11)\n",
    "\n",
    "# Using ThreadPoolExecutor to manage threads\n",
    "with ThreadPoolExecutor(max_workers=4) as executor:\n",
    "    # Submitting tasks to the executor and gathering results\n",
    "    results = list(executor.map(factorial, numbers))\n",
    "\n",
    "# Print the results\n",
    "for num, result in zip(numbers, results):\n",
    "    print(f\"Factorial of {num} is {result}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explanation:\n",
    "1. **`factorial(n)`**: This function calculates the factorial of a given number `n` using Python’s built-in `math.factorial()` function.\n",
    "2. **`ThreadPoolExecutor`**: A thread pool is created to manage up to 4 threads concurrently.\n",
    "3. **`executor.map(factorial, numbers)`**: The `map()` function applies the `factorial()` function to each element in `numbers` (1 to 10) concurrently.\n",
    "4. **Result Handling**: The results are printed out after all tasks are completed.\n",
    "\n",
    "### Notes:\n",
    "- This program calculates the factorial of each number in the range `[1, 10]` concurrently using up to 4 threads. You can adjust the `max_workers` parameter to change the number of concurrent threads.\n",
    "- It is efficient for running tasks concurrently in Jupyter Notebook, as threads do not face the same limitations as processes in Jupyter."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Create a Python program that uses multiprocessing.Pool to compute the square of numbers from 1 to 10 in parallel. Measure the time taken to perform this computation using a pool of different sizes (e.g., 2, 4, 8 processes).\n",
    "\n",
    "The following program calculates the square of numbers from 1 to 10 using multiprocessing and measures the time taken to perform the computation with different pool sizes (2, 4, and 8 processes)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "import multiprocessing\n",
    "import time\n",
    "\n",
    "# Function to calculate the square of a number\n",
    "def square(n):\n",
    "    return n * n\n",
    "\n",
    "# Function to handle multiprocessing with custom task submission\n",
    "def compute_squares_with_pool(pool_size):\n",
    "    # List of numbers to compute squares for\n",
    "    numbers = list(range(1, 11))\n",
    "\n",
    "    # Start the timer\n",
    "    start_time = time.time()\n",
    "\n",
    "    # Create a pool of workers\n",
    "    pool = multiprocessing.Pool(processes=pool_size)\n",
    "\n",
    "    # Submit the tasks to the pool and collect the results\n",
    "    results = pool.map(square, numbers)\n",
    "\n",
    "    # Close the pool and wait for the workers to complete\n",
    "    pool.close()\n",
    "    pool.join()\n",
    "\n",
    "    # End the timer\n",
    "    end_time = time.time()\n",
    "\n",
    "    # Calculate total time taken\n",
    "    total_time = end_time - start_time\n",
    "\n",
    "    return results, total_time\n",
    "\n",
    "# Main entry point to ensure correct behavior in Jupyter\n",
    "if __name__ == '__main__':\n",
    "    pool_sizes = [2, 4, 8]  # Different pool sizes\n",
    "\n",
    "    for pool_size in pool_sizes:\n",
    "        results, total_time = compute_squares_with_pool(pool_size)\n",
    "        print(f\"Pool Size: {pool_size}\")\n",
    "        print(f\"Results: {results}\")\n",
    "        print(f\"Time Taken: {total_time:.4f} seconds\\n\")\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Expected Output:\n",
    "```\n",
    "Pool Size: 2\n",
    "Results: [1, 4, 9, 16, 25, 36, 49, 64, 81, 100]\n",
    "Time Taken: 0.0966 seconds\n",
    "\n",
    "Pool Size: 4\n",
    "Results: [1, 4, 9, 16, 25, 36, 49, 64, 81, 100]\n",
    "Time Taken: 0.0960 seconds\n",
    "\n",
    "Pool Size: 8\n",
    "Results: [1, 4, 9, 16, 25, 36, 49, 64, 81, 100]\n",
    "Time Taken: 0.1342 seconds\n",
    "```\n",
    "\n",
    "### Note:\n",
    "the code is run outside Jupyter Notebook in a `.py` file. Multiprocessing is often better suited for scripts that are executed directly from the command line, as the forking model in Jupyter may interfere with how processes are handled."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explanation:\n",
    "1. **`square(n)`**: A simple function to compute the square of a given number.\n",
    "2. **`measure_time(pool_size)`**: This function takes the pool size (number of processes) as input, calculates the squares of numbers from 1 to 10 in parallel, and returns the time taken.\n",
    "3. **`multiprocessing.Pool(processes=pool_size)`**: Creates a pool of worker processes based on the given `pool_size`.\n",
    "4. **Time Measurement**: The time is measured using `time.time()` before and after the parallel computation to calculate how long it takes.\n",
    "5. **Test Pool Sizes**: The program tests the computation with pool sizes of 2, 4, and 8 processes and prints the results along with the time taken for each pool size.\n",
    "\n",
    "### Notes:\n",
    "- The time taken should decrease as the pool size increases, up to a point where the overhead of managing too many processes becomes a factor.\n",
    "- This code is designed to work well in Jupyter Notebook using `multiprocessing.Pool`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# End of Assignment: Files & Exceptional Handling!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
